{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Np0plMPXRvoq"
   },
   "source": [
    "# Lesson 7 - Schema Proposal for Unstructured Position Management Data\n",
    "\n",
    "In this lesson, you will design agents that propose how to extract information from unstructured position management documents such as emails, chats, SOPs (Standard Operating Procedures), and SLA (Service Level Agreements).\n",
    "\n",
    "You'll learn:\n",
    "- how \"named entity recognition\" can identify trades, positions, accounts, and operational entities in unstructured text\n",
    "- how facts can be extracted as a \"triple\" of subject, predicate and object from operational communications\n",
    "- how to leverage unstructured data to enrich position management knowledge graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b>To access the helper.py, neo4j_for_adk.py and tools.py files :</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/entire_solution.png\" width=\"500\">\n",
    "\n",
    "Two agents to propose data extraction from unstructured position management documents: a \"named entity recognition\" agent and a \"fact extraction\" agent:\n",
    "\n",
    "- Input: `approved_user_goal` (position management requirements), `approved_files` (emails, chats, SOPs, SLAs), `approved_construction_plan` (position hierarchy schema)\n",
    "- Output: \n",
    "    - `approved_entity_types` describing entities like Issues, Breaks, Escalations, Processes, Teams that could be extracted from operational documents\n",
    "    - `approved_fact_types` describing how those entities relate to positions, accounts, and operational workflows\n",
    "- Tools: `get_approved_user_goal`, `get_approved_files`, `get_well_known_types`, `sample_file`, `set_proposed_entities`, `get_proposed_entities`, `approve_proposed_entities`, `add_proposed_fact`, `get_proposed_facts`, `approve_proposed_facts`\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "<img src=\"images/workflow.png\" width=\"500\">\n",
    "\n",
    "Named entity recognition:\n",
    "\n",
    "1. The context is initialized with an `approved_user_goal` (position management), `approved_files` (operational documents) and an `approved_construction_plan` (position hierarchy)\n",
    "2. The agent analyzes unstructured text from emails, chats, SOPs, and SLAs, looking for relevant operational entity types \n",
    "3. The agent proposes a list of entity types (e.g., Issues, Breaks, Processes, Teams), seeking user approval\n",
    "\n",
    "Fact extraction:\n",
    "\n",
    "1. The context now includes `approved_entity_types`\n",
    "2. The agent analyzes unstructured documents, looking for how those entities can be saved as fact triples\n",
    "3. The agent proposes fact types connecting operational entities to position data, seeking user approval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual import of needed libraries, loading of environment variables, and connection to Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 301,
    "id": "sbwxKypOSBkN"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.tools import ToolContext\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 184,
    "id": "MI_qvZJrSJuR"
   },
   "outputs": [],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT_4O)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": [
    "# Check connection to Neo4j by sending a query\n",
    "\n",
    "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "\n",
    "print(neo4j_is_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. Named Entity Recognition (NER) Sub-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NER agent is responsible for proposing entities that could be extracted from unstructured position management documents (emails, chats, SOPs, SLAs).\n",
    "\n",
    "An entity is a person, place, thing, or operational concept that is relevant to position management operations.\n",
    "\n",
    "There are two general kinds of entities:\n",
    "\n",
    "1. Well-known entities: these closely correlate with nodes in the existing structured data\n",
    "   - in position management, this would be things like Trades, Positions, Accounts, Books, LegalEntities, Instruments\n",
    "2. Discovered entities: these are entities that are not pre-defined, but are mentioned in operational documents\n",
    "    - in position management communications, this may be Issues, Breaks, Reconciliation Errors, Escalations, Processes, Teams, Systems, Controls\n",
    "\n",
    "The general goal of the NER agent is to analyze the operational documents and propose entities that are \n",
    "relevant to the user goal of position tracking, break management, and operational risk analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1. Agent Instructions (NER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": [
    "ner_agent_role_and_goal = \"\"\"\n",
    "  You are a top-tier algorithm designed for analyzing operational documents from Global Position Management Operations \n",
    "  in capital markets and proposing the kind of named entities that could be extracted which would be relevant \n",
    "  for position tracking, break management, reconciliation, and operational risk analysis.\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 371
   },
   "outputs": [],
   "source": [
    "ner_agent_hints = \"\"\"\n",
    "  Entities are people, places, things and qualities, but not quantities. \n",
    "  Your goal is to propose a list of the type of entities, not the actual instances\n",
    "  of entities.\n",
    "\n",
    "  There are two general approaches to identifying types of entities:\n",
    "  - well-known entities: these closely correlate with approved node labels in an existing position management graph schema\n",
    "  - discovered entities: these may not exist in the graph schema, but appear consistently in operational documents\n",
    "\n",
    "  **Capital Markets Context:**\n",
    "  \n",
    "  Common discovered entities in position management operations:\n",
    "  - Issue: Problems, breaks, or errors in position data\n",
    "  - ReconciliationBreak: Discrepancies between systems or with external parties\n",
    "  - Escalation: Issues raised to higher management or support\n",
    "  - Process: Operational workflows (e.g., \"EOD Position Reconciliation\", \"Trade Allocation\")\n",
    "  - Team: Operational teams (e.g., \"Position Control\", \"Middle Office\", \"Regulatory Reporting\")\n",
    "  - System: Trading or operations systems (e.g., \"Summit\", \"Calypso\", \"Murex\", \"OMS\")\n",
    "  - Control: Operational controls or checks\n",
    "  - Approval: Authorization workflows\n",
    "  - Exception: Situations requiring manual intervention\n",
    "  - Correction: Fixes applied to position or trade data\n",
    "  - Owner: Responsible party for issues or processes\n",
    "\n",
    "  Design rules for well-known entities:\n",
    "  - always use existing well-known entity types from the position management schema\n",
    "  - prefer reusing existing entity types (Trade, Position, Account, Book, Desk, LegalEntity, Instrument) rather than creating new ones\n",
    "  \n",
    "  Design rules for discovered entities:\n",
    "  - discovered entities are consistently mentioned in operational documents and are highly relevant to position management operations\n",
    "  - always look for entities that would provide more depth or breadth to the existing position graph\n",
    "  - for example, if the graph has \"Position\" nodes, look through the text to discover entities like \"ReconciliationBreak\", \"Issue\", or \"Process\" that explain operational challenges\n",
    "  - avoid quantitative types that may be better represented as a property on an existing entity or relationship\n",
    "  - for example, do not propose \"Amount\" or \"Quantity\" as entity types. Those are better represented as properties on \"Position\" or \"Trade\"\n",
    "  - focus on entities that support operational analysis: root cause of breaks, ownership of issues, process dependencies\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 286
   },
   "outputs": [],
   "source": [
    "ner_agent_chain_of_thought_directions = \"\"\"\n",
    "  Prepare for the task:\n",
    "  - use the 'get_user_goal' tool to get the user goal\n",
    "  - use the 'get_approved_files' tool to get the list of approved files\n",
    "  - use the 'get_well_known_types' tool to get the approved node labels\n",
    "\n",
    "  Think step by step:\n",
    "  1. Sample some of the files using the 'sample_file' tool to understand the content\n",
    "  2. Consider what well-known entities are mentioned in the text\n",
    "  3. Discover entities that are frequently mentioned in the text that support the user's goal\n",
    "  4. Use the 'set_proposed_entities' tool to save the list of well-known and discovered entity types\n",
    "  5. Use the 'get_proposed_entities' tool to retrieve the proposed entities and present them to the user for their approval\n",
    "  6. If the user approves, use the 'approve_proposed_entities' tool to finalize the entity types\n",
    "  7. If the user does not approve, consider their feedback and iterate on the proposal\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 131
   },
   "outputs": [],
   "source": [
    "ner_agent_instruction = f\"\"\"\n",
    "{ner_agent_role_and_goal}\n",
    "{ner_agent_hints}\n",
    "{ner_agent_chain_of_thought_directions}\n",
    "\"\"\"\n",
    "\n",
    "#print(ner_agent_instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2. Tool Definitions (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in previous lessons, you'll define some tools that explictly follow\n",
    "a propose then approve pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 490
   },
   "outputs": [],
   "source": [
    "# tools to propose and approve entity types\n",
    "PROPOSED_ENTITIES = \"proposed_entity_types\"\n",
    "APPROVED_ENTITIES = \"approved_entity_types\"\n",
    "\n",
    "def set_proposed_entities(proposed_entity_types: list[str], tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Sets the list proposed entity types to extract from unstructured text.\"\"\"\n",
    "    tool_context.state[PROPOSED_ENTITIES] = proposed_entity_types\n",
    "    return tool_success(PROPOSED_ENTITIES, proposed_entity_types)\n",
    "\n",
    "def get_proposed_entities(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Gets the list of proposed entity types to extract from unstructured text.\"\"\"\n",
    "    return tool_context.state.get(PROPOSED_ENTITIES, [])\n",
    "\n",
    "def approve_proposed_entities(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Upon approval from user, records the proposed entity types as an approved list of entity types \n",
    "\n",
    "    Only call this tool if the user has explicitly approved the suggested files.\n",
    "    \"\"\"\n",
    "    if PROPOSED_ENTITIES not in tool_context.state:\n",
    "        return tool_error(\"No proposed entity types to approve. Please set proposed entities first, ask for user approval, then call this tool.\")\n",
    "    tool_context.state[APPROVED_ENTITIES] = tool_context.state.get(PROPOSED_ENTITIES)\n",
    "    return tool_success(APPROVED_ENTITIES, tool_context.state[APPROVED_ENTITIES])\n",
    "\n",
    "def get_approved_entities(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Get the approved list of entity types to extract from unstructured text.\"\"\"\n",
    "    return tool_context.state.get(APPROVED_ENTITIES, [])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"well-known entities\" are based on existing node labels used during graph construction.\n",
    "\n",
    "This helper tool will get the existing node labels from the approved construction plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 167
   },
   "outputs": [],
   "source": [
    "def get_well_known_types(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Gets the approved labels that represent well-known entity types in the graph schema.\"\"\"\n",
    "    construction_plan = tool_context.state.get(\"approved_construction_plan\", {})\n",
    "    # approved labels are the keys for each construction plan entry where `construction_type` is \"node\"\n",
    "    approved_labels = {entry[\"label\"] for entry in construction_plan.values() if entry[\"construction_type\"] == \"node\"}\n",
    "    return tool_success(\"approved_labels\", approved_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full toolset includes some existing tools that you'll import\n",
    "plus the extra tools you just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 150
   },
   "outputs": [],
   "source": [
    "from tools import get_approved_user_goal, get_approved_files, sample_file\n",
    "ner_agent_tools = [\n",
    "    get_approved_user_goal, get_approved_files, sample_file,\n",
    "    get_well_known_types,\n",
    "    set_proposed_entities,\n",
    "    approve_proposed_entities\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what the NER agent is working with, use the sample_file tool to look\n",
    "at one of the markdown files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 82
   },
   "outputs": [],
   "source": [
    "file_result = sample_file(\"emails.txt\")\n",
    "\n",
    "print(file_result[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operational documents contain emails, chats, SOPs, and SLAs from the Position Management Operations team that include:\n",
    "- Reconciliation breaks and discrepancies\n",
    "- Escalations to management or support teams\n",
    "- Process descriptions and ownership\n",
    "- System issues and dependencies\n",
    "- Approval workflows and controls\n",
    "\n",
    "For operational risk analysis and break management, you'll be interested in:\n",
    "- Issues that cause position breaks or reconciliation failures\n",
    "- Processes that are critical for accurate position reporting\n",
    "- Teams responsible for various operational tasks\n",
    "- Systems involved in the position management workflow\n",
    "\n",
    "We won't provide explicit instructions about these operational concepts to the agent, instead relying\n",
    "on a combination of the stated user goal along with instruction to find entity types\n",
    "that would support position management operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3. Construct the Sub-agent (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 184
   },
   "outputs": [],
   "source": [
    "NER_AGENT_NAME = \"ner_schema_agent_v1\"\n",
    "ner_schema_agent = Agent(\n",
    "    name=NER_AGENT_NAME,\n",
    "    description=\"Proposes the kind of named entities related to position management operations that could be extracted from operational documents.\",\n",
    "    model=llm,\n",
    "    instruction=ner_agent_instruction,\n",
    "    tools=ner_agent_tools, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial state is important in this phase, as the agent is designed to act\n",
    "within a particular phase of an overall workflow.\n",
    "\n",
    "The NER agent will need:\n",
    "\n",
    "- the user goal, extended to mention operational documents and what operational entities to look for\n",
    "- a list of unstructured files (emails, chats, SOPs, SLAs) that have been pre-approved\n",
    "- the approved construction plan from the structured position management data design phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 677
   },
   "outputs": [],
   "source": [
    "ner_agent_initial_state = {\n",
    "    \"approved_user_goal\": {\n",
    "        \"kind_of_graph\": \"position hierarchy network\",\n",
    "        \"description\": \"\"\"A comprehensive position management graph tracking trades, positions, accounts, books, desks, \n",
    "        and legal entities to support P&L attribution, risk analysis, and regulatory reporting (CCAR, Volcker, FRTB). \n",
    "        Enrich with operational documents (emails, chats, SOPs, SLAs) to identify reconciliation breaks, process dependencies, \n",
    "        team ownership, and system issues affecting position accuracy.\"\"\"\n",
    "    },\n",
    "    \"approved_files\": [\n",
    "        \"emails.txt\",\n",
    "        \"chats.txt\",\n",
    "        \"sop.txt\",\n",
    "        \"sla.txt\"\n",
    "    ],\n",
    "    \"approved_construction_plan\": {\n",
    "        \"Trade\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Trade\",\n",
    "        },\n",
    "        \"Position\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Position\",\n",
    "        },\n",
    "        \"Account\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Account\",\n",
    "        },\n",
    "        \"Book\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Book\",\n",
    "        },\n",
    "        \"Desk\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Desk\",\n",
    "        },\n",
    "        \"LegalEntity\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"LegalEntity\",\n",
    "        },\n",
    "        \"Instrument\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Instrument\",\n",
    "        },\n",
    "        \"Counterparty\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Counterparty\",\n",
    "        }\n",
    "        # Relationship construction omitted, since it won't get used in this notebook\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, you're ready to run the agent. \n",
    "\n",
    "- use the make_agent_caller to create an execution environment\n",
    "- prompt the agent with a single message that should kick-off the analysis\n",
    "- expect the result to be a proposed list of entity types relevant to position management operations\n",
    "- but *not* a list of approved entity types\n",
    "\n",
    "**The entity types here may vary quite a bit. If you're not happy with the proposal,\n",
    "you can run the cell again to get a new list. Look for entities like Issue, ReconciliationBreak, Process, Team, System, etc.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by LLMs can vary with each execution due to their stochastic nature. Your results might differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 405
   },
   "outputs": [],
   "source": [
    "from helper import make_agent_caller\n",
    "\n",
    "ner_agent_caller = await make_agent_caller(ner_schema_agent, ner_agent_initial_state)\n",
    "\n",
    "await ner_agent_caller.call(\"Add operational documents to the position management knowledge graph to identify breaks, issues, processes, and team ownership affecting position accuracy.\")\n",
    "\n",
    "# Alternatively, uncomment this line to get verbose output\n",
    "# await ner_agent_caller.call(\"Add operational documents to identify position management issues.\", True)\n",
    "\n",
    "session_end = await ner_agent_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"\\nSession state: \", session_end.state)\n",
    "\n",
    "if PROPOSED_ENTITIES in session_end.state:\n",
    "    print(\"\\nProposed entities: \", session_end.state[PROPOSED_ENTITIES])\n",
    "\n",
    "if APPROVED_ENTITIES in session_end.state:\n",
    "    print(\"\\nInappropriately approved entities: \", session_end.state[APPROVED_ENTITIES])\n",
    "else:\n",
    "    print(\"\\nAwaiting approval.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "- the agent should identify operational entities like Issue, ReconciliationBreak, Process, Team, System, etc.\n",
    "- if the agent confuses operational processes (like \"Position Reconciliation Process\") with the Position entity itself, that's expected\n",
    "- the agent will see the term \"Position\" in the list of well-known entity types\n",
    "- and it will notice mentions of positions in operational contexts\n",
    "- to fix this, the schema proposal from the previous lesson could save descriptions for each node label to provide more context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you're happy with the proposal, you can tell the agent that you approve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 235
   },
   "outputs": [],
   "source": [
    "await ner_agent_caller.call(\"Approve the proposed entities.\")\n",
    "\n",
    "session_end = await ner_agent_caller.get_session()\n",
    "\n",
    "ner_end_state = session_end.state if session_end else {}\n",
    "\n",
    "print(\"Session state: \", ner_end_state)\n",
    "\n",
    "if APPROVED_ENTITIES in ner_end_state:\n",
    "    print(\"\\nApproved entities: \", ner_end_state[APPROVED_ENTITIES])\n",
    "else:\n",
    "    print(\"\\nStill awaiting approval? That is weird. Please check the agent's state and the proposed entities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. Fact Type Extraction Sub-agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1. Agent Instructions (fact type extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": [
    "fact_agent_role_and_goal = \"\"\"\n",
    "  You are a top-tier algorithm designed for analyzing operational documents from Global Position Management Operations\n",
    "  and proposing the type of facts that could be extracted from text that would be relevant \n",
    "  for understanding position breaks, operational processes, team responsibilities, and system dependencies.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 303
   },
   "outputs": [],
   "source": [
    "fact_agent_hints = \"\"\"\n",
    "  Do not propose specific individual facts, but instead propose the general type \n",
    "  of facts that would be relevant for position management operations. \n",
    "  For example, do not propose \"Position 12345 has Issue ABC\" but the general type of fact \"Position has_issue Issue\".\n",
    "  \n",
    "  Facts are triplets of (subject, predicate, object) where the subject and object are\n",
    "  approved entity types, and the proposed predicate provides information about\n",
    "  how they are related. \n",
    "  \n",
    "  **Capital Markets Examples:**\n",
    "  - (Position, has_issue, Issue)\n",
    "  - (Account, contains, Position)\n",
    "  - (Issue, assigned_to, Team)\n",
    "  - (Process, depends_on, System)\n",
    "  - (ReconciliationBreak, affects, Account)\n",
    "  - (Team, owns, Process)\n",
    "  - (Issue, escalated_to, Desk)\n",
    "  - (System, generates, Position)\n",
    "\n",
    "  Design rules for facts:\n",
    "  - only use approved entity types as subjects or objects. Do not propose new types of entities\n",
    "  - the proposed predicate should describe the relationship between the approved subject and object\n",
    "  - the predicate should optimize for information that is relevant to position management operations:\n",
    "    * Issue tracking and ownership\n",
    "    * Process dependencies and workflows\n",
    "    * System interactions\n",
    "    * Team responsibilities\n",
    "    * Reconciliation break analysis\n",
    "  - the predicate must appear in the source text or be clearly implied. Do not guess.\n",
    "  - use the 'add_proposed_fact' tool to record each proposed fact type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 269
   },
   "outputs": [],
   "source": [
    "fact_agent_chain_of_thought_directions = \"\"\"\n",
    "    Prepare for the task:\n",
    "    - use the 'get_approved_user_goal' tool to get the user goal\n",
    "    - use the 'get_approved_files' tool to get the list of approved files\n",
    "    - use the 'get_approved_entities' tool to get the list of approved entity types\n",
    "\n",
    "    Think step by step:\n",
    "    1. Use the 'get_approved_user_goal' tool to get the user goal\n",
    "    2. Sample some of the approved files using the 'sample_file' tool to understand the content\n",
    "    3. Consider how subjects and objects are related in the text\n",
    "    4. Call the 'add_proposed_fact' tool for each type of fact you propose\n",
    "    5. Use the 'get_proposed_facts' tool to retrieve all the proposed facts\n",
    "    6. Present the proposed types of facts to the user, along with an explanation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 97
   },
   "outputs": [],
   "source": [
    "fact_agent_instruction = f\"\"\"\n",
    "{fact_agent_role_and_goal}\n",
    "{fact_agent_hints}\n",
    "{fact_agent_chain_of_thought_directions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2. Tool Definitions (fact type extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 881
   },
   "outputs": [],
   "source": [
    "PROPOSED_FACTS = \"proposed_fact_types\"\n",
    "APPROVED_FACTS = \"approved_fact_types\"\n",
    "\n",
    "def add_proposed_fact(approved_subject_label:str,\n",
    "                      proposed_predicate_label:str,\n",
    "                      approved_object_label:str,\n",
    "                      tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Add a proposed type of fact that could be extracted from the files.\n",
    "\n",
    "    A proposed fact type is a tuple of (subject, predicate, object) where\n",
    "    the subject and object are approved entity types and the predicate \n",
    "    is a proposed relationship label.\n",
    "\n",
    "    Args:\n",
    "      approved_subject_label: approved label of the subject entity type\n",
    "      proposed_predicate_label: label of the predicate\n",
    "      approved_object_label: approved label of the object entity type\n",
    "    \"\"\"\n",
    "    # Guard against invalid labels\n",
    "    approved_entities = tool_context.state.get(APPROVED_ENTITIES, [])\n",
    "    \n",
    "    if approved_subject_label not in approved_entities:\n",
    "        return tool_error(f\"Approved subject label {approved_subject_label} not found. Try again.\")\n",
    "    if approved_object_label not in approved_entities:\n",
    "        return tool_error(f\"Approved object label {approved_object_label} not found. Try again.\")\n",
    "    \n",
    "    current_predicates = tool_context.state.get(PROPOSED_FACTS, {})\n",
    "    current_predicates[proposed_predicate_label] = {\n",
    "        \"subject_label\": approved_subject_label,\n",
    "        \"predicate_label\": proposed_predicate_label,\n",
    "        \"object_label\": approved_object_label\n",
    "    }\n",
    "    tool_context.state[PROPOSED_FACTS] = current_predicates\n",
    "    return tool_success(PROPOSED_FACTS, current_predicates)\n",
    "    \n",
    "def get_proposed_facts(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Get the proposed types of facts that could be extracted from the files.\"\"\"\n",
    "    return tool_context.state.get(PROPOSED_FACTS, {})\n",
    "\n",
    "\n",
    "def approve_proposed_facts(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Upon user approval, records the proposed fact types as approved fact types\n",
    "\n",
    "    Only call this tool if the user has explicitly approved the proposed fact types.\n",
    "    \"\"\"\n",
    "    if PROPOSED_FACTS not in tool_context.state:\n",
    "        return tool_error(\"No proposed fact types to approve. Please set proposed facts first, ask for user approval, then call this tool.\")\n",
    "    tool_context.state[APPROVED_FACTS] = tool_context.state.get(PROPOSED_FACTS)\n",
    "    return tool_success(APPROVED_FACTS, tool_context.state[APPROVED_FACTS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 148
   },
   "outputs": [],
   "source": [
    "fact_agent_tools = [\n",
    "    get_approved_user_goal, get_approved_files, \n",
    "    get_approved_entities,\n",
    "    sample_file,\n",
    "    add_proposed_fact,\n",
    "    get_proposed_facts,\n",
    "    approve_proposed_facts\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3. Construct the Sub-agent (fact type extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 184
   },
   "outputs": [],
   "source": [
    "FACT_AGENT_NAME = \"fact_type_extraction_agent_v1\"\n",
    "relevant_fact_agent = Agent(\n",
    "    name=FACT_AGENT_NAME,\n",
    "    description=\"Proposes the kind of relevant operational facts about position management that could be extracted from operational documents.\",\n",
    "    model=llm,\n",
    "    instruction=fact_agent_instruction,\n",
    "    tools=fact_agent_tools, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by LLMs can vary with each execution due to their stochastic nature. Your results might differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 490
   },
   "outputs": [],
   "source": [
    "# make a copy of the NER agent's end state to use as the initial state for the fact agent\n",
    "fact_agent_initial_state = ner_end_state.copy()\n",
    "\n",
    "fact_agent_caller = await make_agent_caller(relevant_fact_agent, fact_agent_initial_state)\n",
    "\n",
    "await fact_agent_caller.call(\"Propose fact types that can be found in the operational documents to connect issues, processes, teams, and systems to position data.\")\n",
    "# await fact_agent_caller.call(\"Propose fact types that can be found in the operational documents.\", True)\n",
    "\n",
    "session_end = await fact_agent_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"\\nSession state: \", session_end.state)\n",
    "\n",
    "print(\"\\nApproved entities: \", session_end.state.get(APPROVED_ENTITIES, []))\n",
    "\n",
    "# Check that the agent proposed facts\n",
    "if PROPOSED_FACTS in session_end.state:\n",
    "    print(\"\\nCorrectly proposed facts: \", session_end.state[PROPOSED_FACTS])\n",
    "else:\n",
    "    print(\"\\nProposed facts not found in session state. What went wrong?\")\n",
    "\n",
    "# Check that the agent did not inappropriately approve facts\n",
    "if APPROVED_FACTS in session_end.state:\n",
    "    print(\"\\nInappriately approved facts: \", session_end.state[APPROVED_FACTS])\n",
    "else:\n",
    "    print(\"\\nApproved facts not found in session state, which is good.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're happy with the fact type proposal, approve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 201
   },
   "outputs": [],
   "source": [
    "await fact_agent_caller.call(\"Approve the proposed fact types.\")\n",
    "\n",
    "session_end = await fact_agent_caller.get_session()\n",
    "\n",
    "print(\"Session state: \", session_end.state)\n",
    "\n",
    "if APPROVED_FACTS in session_end.state:\n",
    "    print(\"\\nApproved fact types: \", session_end.state[APPROVED_FACTS])\n",
    "else:\n",
    "    print(\"\\nFailed to approve fact types.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
