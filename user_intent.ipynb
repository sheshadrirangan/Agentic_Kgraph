{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4 - Understanding User Intent for Global Position Management Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, you will build the first agent of your multi-agent system, which will be the user intent agent.\n",
    "\n",
    "You'll learn:\n",
    "\n",
    "- how to give an agent a clear task\n",
    "- how to define tools that are appropriate for the task\n",
    "- how use state to save important information\n",
    "\n",
    "Along the way, you will get experience with basic human-in-the-loop interaction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>To access the helper.py and neo4j_for_adk.py files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Agent Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/entire_solution.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user intent agent is a goal-oriented, conversational agent that helps the Global Position Management Operations team ideate on the kind of graph to build for capital markets operations.\n",
    "- Input: nothing\n",
    "- Output: `approved_user_goal`, a dictionary pairing a kind of graph with a description of the purpose of the graph.\n",
    "- Tools: `set_perceived_user_goal`, `approve_perceived_user_goal`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Each lesson will focus on one part of the multi-agent system (as shown in the above image). The end-to-end solution will be available in this [repo](https://github.com/neo4j-contrib/agentic-kg). If the repo is empty, it means that the project is still in progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual import of needed libraries, loading of environment variables, and connection to Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sbwxKypOSBkN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.tools import ToolContext\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from networkx_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MI_qvZJrSJuR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ MOCK MODE: Using test responses (no real LLM)\n",
      "Testing model: MOCK MODE\n",
      "{'choices': [{'message': {'content': \"Mock response: Yes, I'm ready!\"}}]}\n",
      "\n",
      "‚úÖ Mock LLM is ready!\n"
     ]
    }
   ],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "\n",
    "# Option 1: OpenAI (Requires paid API key)\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "\n",
    "# Option 2: Groq (FREE - Fast & Generous free tier)\n",
    "# Get free API key from: https://console.groq.com\n",
    "# Set in .env: GROQ_API_KEY=your_key_here\n",
    "MODEL_GROQ = \"groq/llama-3.1-70b-versatile\"\n",
    "\n",
    "# Option 3: Google Gemini (FREE tier available)\n",
    "# Get free API key from: https://makersuite.google.com/app/apikey\n",
    "# Set in .env: GEMINI_API_KEY=your_key_here\n",
    "MODEL_GEMINI = \"gemini/gemini-1.5-flash\"\n",
    "\n",
    "# Option 4: Ollama (FREE - Runs locally, no API key needed)\n",
    "# Install Ollama from: https://ollama.com\n",
    "# Run: ollama pull llama3.2\n",
    "MODEL_OLLAMA = \"ollama/llama3.2\"\n",
    "\n",
    "# Option 5: Mock/Test Mode (No API needed - for testing workflow)\n",
    "# This uses a simple mock that returns test responses\n",
    "USE_MOCK_MODE = True  # Set to True if you can't connect to any API\n",
    "\n",
    "# Choose your model here:\n",
    "SELECTED_MODEL = MODEL_OLLAMA  # Changed to Ollama for offline use\n",
    "\n",
    "if USE_MOCK_MODE:\n",
    "    print(\"üß™ MOCK MODE: Using test responses (no real LLM)\")\n",
    "    # Create a simple mock LLM for testing\n",
    "    class MockLLM:\n",
    "        def __init__(self):\n",
    "            self.model = \"mock/test\"\n",
    "            self.llm_client = self\n",
    "        \n",
    "        def completion(self, **kwargs):\n",
    "            return {\"choices\": [{\"message\": {\"content\": \"Mock response: Yes, I'm ready!\"}}]}\n",
    "    \n",
    "    llm = MockLLM()\n",
    "else:\n",
    "    llm = LiteLlm(model=SELECTED_MODEL)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "try:\n",
    "    print(f\"Testing model: {SELECTED_MODEL if not USE_MOCK_MODE else 'MOCK MODE'}\")\n",
    "    result = llm.llm_client.completion(model=llm.model, messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], tools=[])\n",
    "    print(result)\n",
    "    print(f\"\\n‚úÖ {SELECTED_MODEL if not USE_MOCK_MODE else 'Mock LLM'} is ready!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error connecting to {SELECTED_MODEL}\")\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"\\nüí° Solutions:\")\n",
    "    print(\"1. If offline: Install Ollama from https://ollama.com and run 'ollama pull llama3.2'\")\n",
    "    print(\"2. If you have internet: Get free API key from https://console.groq.com\")\n",
    "    print(\"3. For testing only: Set USE_MOCK_MODE = True above (line 25)\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Troubleshooting Connection Issues\n",
    "\n",
    "If you see **\"getaddrinfo failed\"** or **\"connection error\"**, you have 3 options:\n",
    "\n",
    "### Option 1: Ollama (Local - No Internet) ‚≠ê Recommended for Offline\n",
    "1. Download from: https://ollama.com/download\n",
    "2. Install and run: `ollama pull llama3.2`\n",
    "3. Set `SELECTED_MODEL = MODEL_OLLAMA` in cell below\n",
    "4. No API key needed!\n",
    "\n",
    "### Option 2: Groq (Cloud - Requires Internet)\n",
    "1. Visit: https://console.groq.com/keys\n",
    "2. Get free API key\n",
    "3. Add to `.env` file: `GROQ_API_KEY=your_key`\n",
    "4. Set `SELECTED_MODEL = MODEL_GROQ`\n",
    "\n",
    "### Option 3: Mock Mode (Testing Only)\n",
    "- Set `USE_MOCK_MODE = True` in cell below\n",
    "- Workflow will work but won't have real AI responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAM0BqGWSTo5"
   },
   "source": [
    "## 4.3. Define the User Intent Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Agent Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will define the instructions for the agent one part at a time, then combine them into a final set of instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the role and goal for the user intent agent\n",
    "agent_role_and_goal = \"\"\"\n",
    "    You are an expert at knowledge graph use cases for capital markets and investment banking operations. \n",
    "    Your primary goal is to help the Global Position Management Operations team come up with a knowledge graph use case \n",
    "    that supports their operational, risk management, and regulatory compliance needs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the agent some hints about what to say\n",
    "agent_conversational_hints = \"\"\"\n",
    "    If the user is unsure what to do, make some suggestions based on capital markets use cases like:\n",
    "    - position aggregation network showing relationships between trades, positions, accounts, books, and legal entities\n",
    "    - counterparty risk network tracking exposures, collateral, and credit relationships across trading partners\n",
    "    - securities master data graph connecting instruments, issuers, exchanges, and reference data sources\n",
    "    - reconciliation and break management system tracking discrepancies across internal systems and external custodians\n",
    "    - regulatory reporting lineage showing data flows from source systems through transformations to regulatory submissions\n",
    "    - collateral optimization network modeling eligible securities, haircuts, and collateral agreements\n",
    "    - corporate actions impact analysis tracking entitlements, positions, and downstream effects\n",
    "    - settlement and clearing workflow with SSIs (Standard Settlement Instructions), nostro accounts, and CSDs (Central Securities Depositories)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe what the output should look like\n",
    "agent_output_definition = \"\"\"\n",
    "    A user goal has two components:\n",
    "    - kind_of_graph: at most 3-4 words describing the graph, for example \"position hierarchy network\" or \"counterparty risk graph\"\n",
    "    - description: a few sentences about the intention of the graph, for example \"A comprehensive view of position aggregation across trading books, legal entities, and regulatory reporting hierarchies.\" or \"Real-time counterparty exposure tracking with collateral and netting set relationships for credit risk management.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the steps the agent should follow\n",
    "agent_chain_of_thought_directions = \"\"\"\n",
    "    Think carefully and collaborate with the user:\n",
    "    1. Understand the user's goal, which is a kind_of_graph with description\n",
    "    2. Ask clarifying questions as needed\n",
    "    3. When you think you understand their goal, use the 'set_perceived_user_goal' tool to record your perception\n",
    "    4. Present the perceived user goal to the user for confirmation\n",
    "    5. If the user agrees, use the 'approve_perceived_user_goal' tool to approve the user goal. This will save the goal in state under the 'approved_user_goal' key.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    You are an expert at knowledge graph use cases for capital markets and investment banking operations. \n",
      "    Your primary goal is to help the Global Position Management Operations team come up with a knowledge graph use case \n",
      "    that supports their operational, risk management, and regulatory compliance needs.\n",
      "\n",
      "\n",
      "    If the user is unsure what to do, make some suggestions based on capital markets use cases like:\n",
      "    - position aggregation network showing relationships between trades, positions, accounts, books, and legal entities\n",
      "    - counterparty risk network tracking exposures, collateral, and credit relationships across trading partners\n",
      "    - securities master data graph connecting instruments, issuers, exchanges, and reference data sources\n",
      "    - reconciliation and break management system tracking discrepancies across internal systems and external custodians\n",
      "    - regulatory reporting lineage showing data flows from source systems through transformations to regulatory submissions\n",
      "    - collateral optimization network modeling eligible securities, haircuts, and collateral agreements\n",
      "    - corporate actions impact analysis tracking entitlements, positions, and downstream effects\n",
      "    - settlement and clearing workflow with SSIs (Standard Settlement Instructions), nostro accounts, and CSDs (Central Securities Depositories)\n",
      "\n",
      "\n",
      "    A user goal has two components:\n",
      "    - kind_of_graph: at most 3-4 words describing the graph, for example \"position hierarchy network\" or \"counterparty risk graph\"\n",
      "    - description: a few sentences about the intention of the graph, for example \"A comprehensive view of position aggregation across trading books, legal entities, and regulatory reporting hierarchies.\" or \"Real-time counterparty exposure tracking with collateral and netting set relationships for credit risk management.\"\n",
      "\n",
      "\n",
      "    Think carefully and collaborate with the user:\n",
      "    1. Understand the user's goal, which is a kind_of_graph with description\n",
      "    2. Ask clarifying questions as needed\n",
      "    3. When you think you understand their goal, use the 'set_perceived_user_goal' tool to record your perception\n",
      "    4. Present the perceived user goal to the user for confirmation\n",
      "    5. If the user agrees, use the 'approve_perceived_user_goal' tool to approve the user goal. This will save the goal in state under the 'approved_user_goal' key.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# combine all the instruction components into one complete instruction...\n",
    "complete_agent_instruction = f\"\"\"\n",
    "{agent_role_and_goal}\n",
    "{agent_conversational_hints}\n",
    "{agent_output_definition}\n",
    "{agent_chain_of_thought_directions}\n",
    "\"\"\"\n",
    "\n",
    "print(complete_agent_instruction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Tool Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tools to define the user goal helps the agent focus on the requirements. \n",
    "\n",
    "Rather than open-ended prose, the user goal is defined with specifc arguments passed to a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Set Perceived User Goal\n",
    "# to encourage collaboration with the user, the first tool only sets the perceived user goal\n",
    "\n",
    "PERCEIVED_USER_GOAL = \"perceived_user_goal\"\n",
    "\n",
    "def set_perceived_user_goal(kind_of_graph: str, graph_description:str, tool_context: ToolContext):\n",
    "    \"\"\"Sets the perceived user's goal, including the kind of graph and its description.\n",
    "    \n",
    "    Args:\n",
    "        kind_of_graph: 2-4 word definition of the kind of graph, for example \"position management hierarchy\" or \"counterparty exposure network\"\n",
    "        graph_description: a single paragraph description of the graph, summarizing the user's intent and operational objectives\n",
    "    \"\"\"\n",
    "    user_goal_data = {\"kind_of_graph\": kind_of_graph, \"graph_description\": graph_description}\n",
    "    tool_context.state[PERCEIVED_USER_GOAL] = user_goal_data\n",
    "    return tool_success(PERCEIVED_USER_GOAL, user_goal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Approve the perceived user goal\n",
    "# approval from the user should trigger a call to this tool\n",
    "\n",
    "APPROVED_USER_GOAL = \"approved_user_goal\"\n",
    "\n",
    "def approve_perceived_user_goal(tool_context: ToolContext):\n",
    "    \"\"\"Upon approval from user, will record the perceived user goal as the approved user goal.\n",
    "    \n",
    "    Only call this tool if the user has explicitly approved the perceived user goal.\n",
    "    \"\"\"\n",
    "    # Trust, but verify. \n",
    "    # Require that the perceived goal was set before approving it. \n",
    "    # Notice the tool error helps the agent take\n",
    "    if PERCEIVED_USER_GOAL not in tool_context.state:\n",
    "        return tool_error(\"perceived_user_goal not set. Set perceived user goal first, or ask clarifying questions if you are unsure.\")\n",
    "    \n",
    "    tool_context.state[APPROVED_USER_GOAL] = tool_context.state[PERCEIVED_USER_GOAL]\n",
    "\n",
    "    return tool_success(APPROVED_USER_GOAL, tool_context.state[APPROVED_USER_GOAL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the tools to a list\n",
    "user_intent_agent_tools = [set_perceived_user_goal, approve_perceived_user_goal]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Agent Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for LlmAgent\nmodel.str\n  Input should be a valid string [type=string_type, input_value=<__main__.MockLLM object at 0x000001DD1AC6F680>, input_type=MockLLM]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\nmodel.BaseLlm\n  Input should be a valid dictionary or instance of BaseLlm [type=model_type, input_value=<__main__.MockLLM object at 0x000001DD1AC6F680>, input_type=MockLLM]\n    For further information visit https://errors.pydantic.dev/2.12/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Finally, construct the agent\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m user_intent_agent = \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser_intent_agent_v1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# a unique, versioned name\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# defined earlier in a variable\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHelps the user ideate on a knowledge graph use case.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# used for delegation\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstruction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomplete_agent_instruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# the complete instructions you composed earlier\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_intent_agent_tools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# the list of tools\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAgent \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_intent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m created.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\svenkate012816\\.conda\\envs\\kgraph_env\\Lib\\site-packages\\pydantic\\main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 2 validation errors for LlmAgent\nmodel.str\n  Input should be a valid string [type=string_type, input_value=<__main__.MockLLM object at 0x000001DD1AC6F680>, input_type=MockLLM]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\nmodel.BaseLlm\n  Input should be a valid dictionary or instance of BaseLlm [type=model_type, input_value=<__main__.MockLLM object at 0x000001DD1AC6F680>, input_type=MockLLM]\n    For further information visit https://errors.pydantic.dev/2.12/v/model_type"
     ]
    }
   ],
   "source": [
    "# Finally, construct the agent\n",
    "\n",
    "user_intent_agent = Agent(\n",
    "    name=\"user_intent_agent_v1\", # a unique, versioned name\n",
    "    model=llm, # defined earlier in a variable\n",
    "    description=\"Helps the user ideate on a knowledge graph use case.\", # used for delegation\n",
    "    instruction=complete_agent_instruction, # the complete instructions you composed earlier\n",
    "    tools=user_intent_agent_tools, # the list of tools\n",
    ")\n",
    "\n",
    "print(f\"Agent '{user_intent_agent.name}' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zKGVwRkSduA"
   },
   "source": [
    "## 4.4. Interact with the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZJr8lbkSebH"
   },
   "outputs": [],
   "source": [
    "# use a helper to create an agent execution environment\n",
    "from helper import make_agent_caller\n",
    "\n",
    "# NOTE: if re-running the session, come back here to re-initialize the agent\n",
    "user_intent_caller = await make_agent_caller(user_intent_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEd2QhHyUKY8"
   },
   "outputs": [],
   "source": [
    "# Run the Initial Conversation\n",
    "\n",
    "session_start = await user_intent_caller.get_session()\n",
    "print(f\"Session Start: {session_start.state}\") # expect this to be empty\n",
    "\n",
    "# We need an async function to await for each conversation\n",
    "async def run_conversation():\n",
    "    # start things off by describing your goal\n",
    "    await user_intent_caller.call(\"\"\"I'd like a position management hierarchy graph that tracks the complete lineage from individual trades \n",
    "    up through positions, books, desks, legal entities, and regulatory reporting structures. This should support position reconciliation, \n",
    "    P&L attribution, and regulatory reporting (e.g., CCAR, Volcker, FRTB).\"\"\") \n",
    "\n",
    "    if PERCEIVED_USER_GOAL not in session_start.state:\n",
    "        # the LLM may have asked a clarifying question. offer some more details\n",
    "        await user_intent_caller.call(\"\"\"We need to handle complex scenarios like inter-desk transfers, novations, and real-time \n",
    "        position updates across multiple asset classes including equities, fixed income, derivatives, and FX.\"\"\")        \n",
    "\n",
    "    # Optimistically presume approval.\n",
    "    await user_intent_caller.call(\"Approve that goal.\", True)\n",
    "\n",
    "await run_conversation()\n",
    "\n",
    "session_end = await user_intent_caller.get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbUzAGvsmB2a"
   },
   "source": [
    "Take a close look at the session state.\n",
    "\n",
    "- session state starts empty, as you'd expect since we did not initialize it\n",
    "- after the conversation, there are two values in session state: `perceived_user_goal` and `approved_user_goal`\n",
    "- this duplication is intentional, separating \"working memory\" from work specification\n",
    "- subsequent steps in the workflow should only use approved work specifications\n",
    "- in production, work specifications should be persisted to enable tracing and reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Optional - Sequence diagram illustrating the workflow of  \"User Intent Agent\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/user_intent_diag.png\"  width=600> "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "kgraph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
