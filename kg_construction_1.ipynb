{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Np0plMPXRvoq"
   },
   "source": [
    "# Lesson 8 - Position Management Knowledge Graph Construction - Part I\n",
    "\n",
    "With all the plans in place, it's time to construct the position management knowledge graph. \n",
    "\n",
    "For the **position domain graph** construction, no agent is required. The construction plan has all the information needed to drive a rule-based import of position hierarchy data.\n",
    "\n",
    "<img src=\"images/domain.png\" width=\"600\">\n",
    "\n",
    "**Note**: This notebook uses Cypher queries to build the position management domain graph from CSV files containing trades, positions, accounts, books, desks, legal entities, and instruments. Don't worry if you're unfamiliar with Cypher â€” focus on understanding the big picture of how the structured position data is transformed into a graph structure based on the construction plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single tool which will build a position management knowledge graph using the defined construction rules.\n",
    "- Input: `approved_construction_plan` (position hierarchy schema)\n",
    "- Output: a position domain graph in Neo4j with trades, positions, accounts, books, desks, legal entities, and instruments\n",
    "- Tools: `construct_domain_graph` + helper functions\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "1. The context is initialized with an `approved_construction_plan` for position management and `approved_files`\n",
    "2. Process all the node construction rules (Trade, Position, Account, Book, Desk, LegalEntity, Instrument, Counterparty)\n",
    "3. Process all the relationship construction rules (BELONGS_TO, ALLOCATED_TO, REFERENCES, TRADES_WITH, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual import of needed libraries, loading of environment variables, and connection to Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 301,
    "id": "sbwxKypOSBkN"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "from typing import Dict, Any\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 184,
    "id": "MI_qvZJrSJuR"
   },
   "outputs": [],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT_4O)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": [
    "# Check connection to Neo4j by sending a query\n",
    "\n",
    "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "\n",
    "print(neo4j_is_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3. Tool Definitions (Domain Graph Construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `construct_domain_graph` tool is responsible for constructing the \"position management domain graph\" from CSV files,\n",
    "according to the approved construction plan for capital markets position hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: create_uniqueness_constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This function creates a uniqueness constraint in Neo4j to prevent duplicate nodes with the same label and property value from being created. This is critical for position management data to ensure unique trades, positions, accounts, and instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 439
   },
   "outputs": [],
   "source": [
    "def create_uniqueness_constraint(\n",
    "    label: str,\n",
    "    unique_property_key: str,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Creates a uniqueness constraint for a node label and property key.\n",
    "    A uniqueness constraint ensures that no two nodes with the same label and property key have the same value.\n",
    "    This improves the performance and integrity of data import and later queries.\n",
    "\n",
    "    Args:\n",
    "        label: The label of the node to create a constraint for.\n",
    "        unique_property_key: The property key that should have a unique value.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with a status key ('success' or 'error').\n",
    "        On error, includes an 'error_message' key.\n",
    "    \"\"\"    \n",
    "    # Use string formatting since Neo4j doesn't support parameterization of labels and property keys when creating a constraint\n",
    "    constraint_name = f\"{label}_{unique_property_key}_constraint\"\n",
    "    query = f\"\"\"CREATE CONSTRAINT `{constraint_name}` IF NOT EXISTS\n",
    "    FOR (n:`{label}`)\n",
    "    REQUIRE n.`{unique_property_key}` IS UNIQUE\"\"\"\n",
    "    results = graphdb.send_query(query)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: load_nodes_from_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function performs batch loading of position management nodes from a CSV file into Neo4j. It uses the `LOAD CSV` command with the `MERGE` operation to create nodes (trades, positions, accounts, etc.) while avoiding duplicates based on the unique column (trade_id, position_id, account_id, etc.). The Cypher query processes data in batches of 1000 rows for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The csv files are stored in the `/import` directory of `neo4j` database. When you use the query `LOAD CSV from \"file:///\" + $source_file`, neo4j checks the `/import` directory by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 439
   },
   "outputs": [],
   "source": [
    "def load_nodes_from_csv(\n",
    "    source_file: str,\n",
    "    label: str,\n",
    "    unique_column_name: str,\n",
    "    properties: list[str],\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Batch loading of nodes from a CSV file\"\"\"\n",
    "\n",
    "    # load nodes from CSV file by merging on the unique_column_name value\n",
    "    query = f\"\"\"LOAD CSV WITH HEADERS FROM \"file:///\" + $source_file AS row\n",
    "    CALL (row) {{\n",
    "        MERGE (n:$($label) {{ {unique_column_name} : row[$unique_column_name] }})\n",
    "        FOREACH (k IN $properties | SET n[k] = row[k])\n",
    "    }} IN TRANSACTIONS OF 1000 ROWS\n",
    "    \"\"\"\n",
    "\n",
    "    results = graphdb.send_query(query, {\n",
    "        \"source_file\": source_file,\n",
    "        \"label\": label,\n",
    "        \"unique_column_name\": unique_column_name,\n",
    "        \"properties\": properties\n",
    "    })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Position Management Domain Graph Construction\n",
    "\n",
    "This cell executes the main construction function using the approved construction plan. It builds the complete position management knowledge graph by importing all nodes (trades, positions, accounts, books, desks, legal entities, instruments) and relationships (position hierarchies, allocations, instrument references) according to the defined rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: import_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function orchestrates the node import process for position management entities by first creating a uniqueness constraint (e.g., on trade_id, position_id, account_id) and then loading nodes from the CSV file. It ensures data integrity by establishing constraints before importing position data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 369
   },
   "outputs": [],
   "source": [
    "def import_nodes(node_construction: dict) -> dict:\n",
    "    \"\"\"Import nodes as defined by a node construction rule.\"\"\"\n",
    "\n",
    "    # create a uniqueness constraint for the unique_column\n",
    "    uniqueness_result = create_uniqueness_constraint(\n",
    "        node_construction[\"label\"],\n",
    "        node_construction[\"unique_column_name\"]\n",
    "    )\n",
    "\n",
    "    if (uniqueness_result[\"status\"] == \"error\"):\n",
    "        return uniqueness_result\n",
    "\n",
    "    # import nodes from csv\n",
    "    load_nodes_result = load_nodes_from_csv(\n",
    "        node_construction[\"source_file\"],\n",
    "        node_construction[\"label\"],\n",
    "        node_construction[\"unique_column_name\"],\n",
    "        node_construction[\"properties\"]\n",
    "    )\n",
    "\n",
    "    return load_nodes_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: import_relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function imports relationships between position management nodes from a CSV file. It uses a Cypher query that matches existing nodes (trades, positions, accounts, books, desks, legal entities) and creates relationships between them (BELONGS_TO, ALLOCATED_TO, REFERENCES, etc.). The query finds pairs of nodes and creates relationships with specified properties (quantities, allocation percentages, timestamps) between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 456
   },
   "outputs": [],
   "source": [
    "def import_relationships(relationship_construction: dict) -> Dict[str, Any]:\n",
    "    \"\"\"Import relationships as defined by a relationship construction rule.\"\"\"\n",
    "\n",
    "    # load nodes from CSV file by merging on the unique_column_name value \n",
    "    from_node_column = relationship_construction[\"from_node_column\"]\n",
    "    to_node_column = relationship_construction[\"to_node_column\"]\n",
    "    query = f\"\"\"LOAD CSV WITH HEADERS FROM \"file:///\" + $source_file AS row\n",
    "    CALL (row) {{\n",
    "        MATCH (from_node:$($from_node_label) {{ {from_node_column} : row[$from_node_column] }}),\n",
    "              (to_node:$($to_node_label) {{ {to_node_column} : row[$to_node_column] }} )\n",
    "        MERGE (from_node)-[r:$($relationship_type)]->(to_node)\n",
    "        FOREACH (k IN $properties | SET r[k] = row[k])\n",
    "    }} IN TRANSACTIONS OF 1000 ROWS\n",
    "    \"\"\"\n",
    "    \n",
    "    results = graphdb.send_query(query, {\n",
    "        \"source_file\": relationship_construction[\"source_file\"],\n",
    "        \"from_node_label\": relationship_construction[\"from_node_label\"],\n",
    "        \"from_node_column\": relationship_construction[\"from_node_column\"],\n",
    "        \"to_node_label\": relationship_construction[\"to_node_label\"],\n",
    "        \"to_node_column\": relationship_construction[\"to_node_column\"],\n",
    "        \"relationship_type\": relationship_construction[\"relationship_type\"],\n",
    "        \"properties\": relationship_construction[\"properties\"]\n",
    "    })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: construct_domain_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main orchestration function that builds the entire position management domain graph. It processes the construction plan in two phases:\n",
    "1. **Node Construction**: First imports all position management nodes (Trade, Position, Account, Book, Desk, LegalEntity, Instrument, Counterparty) to ensure they exist before creating relationships\n",
    "2. **Relationship Construction**: Then creates relationships between the existing nodes (BELONGS_TO for hierarchy, ALLOCATED_TO for allocations, REFERENCES for instruments, etc.)\n",
    "\n",
    "This two-phase approach prevents relationship creation failures due to missing nodes and ensures proper position hierarchy construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 218
   },
   "outputs": [],
   "source": [
    "def construct_domain_graph(construction_plan: dict) -> Dict[str, Any]:\n",
    "    \"\"\"Construct a domain graph according to a construction plan.\"\"\"\n",
    "    # first, import nodes\n",
    "    node_constructions = [value for value in construction_plan.values() if value['construction_type'] == 'node']\n",
    "    for node_construction in node_constructions:\n",
    "        import_nodes(node_construction)\n",
    "\n",
    "    # second, import relationships\n",
    "    relationship_constructions = [value for value in construction_plan.values() if value['construction_type'] == 'relationship']\n",
    "    for relationship_construction in relationship_constructions:\n",
    "        import_relationships(relationship_construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4. Run construct_domain_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines the approved construction plan as a dictionary containing rules for creating position management nodes and relationships. The plan includes:\n",
    "\n",
    "- **Node Rules**: Define how to create Trade, Position, Account, Book, Desk, LegalEntity, Instrument, and Counterparty nodes from CSV files\n",
    "- **Relationship Rules**: Define how to create BELONGS_TO (position hierarchy), ALLOCATED_TO (trade allocations), REFERENCES (instrument links), and TRADES_WITH (counterparty) relationships\n",
    "\n",
    "Each rule specifies the source file, labels, unique identifiers (trade_id, position_id, account_id, etc.), and properties (quantities, amounts, timestamps) to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 1085
   },
   "outputs": [],
   "source": [
    "# the approved construction plan for position management should look something like this...\n",
    "approved_construction_plan = {\n",
    "    \"Trade\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"trades.csv\", \n",
    "        \"label\": \"Trade\", \n",
    "        \"unique_column_name\": \"trade_id\", \n",
    "        \"properties\": [\"trade_date\", \"trade_type\", \"quantity\", \"price\", \"amount\", \"currency\", \"trader_id\", \"book_id\", \"instrument_id\", \"counterparty_id\"]\n",
    "    }, \n",
    "    \"Position\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"positions.csv\", \n",
    "        \"label\": \"Position\", \n",
    "        \"unique_column_name\": \"position_id\", \n",
    "        \"properties\": [\"position_date\", \"quantity\", \"market_value\", \"currency\", \"account_id\", \"instrument_id\"]\n",
    "    }, \n",
    "    \"Account\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"accounts.csv\", \n",
    "        \"label\": \"Account\", \n",
    "        \"unique_column_name\": \"account_id\", \n",
    "        \"properties\": [\"account_number\", \"account_name\", \"account_type\", \"book_id\", \"opening_date\"]\n",
    "    }, \n",
    "    \"Book\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"books.csv\", \n",
    "        \"label\": \"Book\", \n",
    "        \"unique_column_name\": \"book_id\", \n",
    "        \"properties\": [\"book_code\", \"book_name\", \"desk_id\", \"region\"]\n",
    "    },\n",
    "    \"Desk\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"desks.csv\", \n",
    "        \"label\": \"Desk\", \n",
    "        \"unique_column_name\": \"desk_id\", \n",
    "        \"properties\": [\"desk_name\", \"desk_type\", \"legal_entity_id\", \"location\"]\n",
    "    },\n",
    "    \"LegalEntity\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"legal_entities.csv\", \n",
    "        \"label\": \"LegalEntity\", \n",
    "        \"unique_column_name\": \"entity_id\", \n",
    "        \"properties\": [\"entity_name\", \"lei_code\", \"jurisdiction\", \"regulatory_status\"]\n",
    "    },\n",
    "    \"Instrument\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"instruments.csv\", \n",
    "        \"label\": \"Instrument\", \n",
    "        \"unique_column_name\": \"instrument_id\", \n",
    "        \"properties\": [\"isin\", \"cusip\", \"ticker\", \"instrument_name\", \"asset_class\", \"currency\", \"issuer\"]\n",
    "    },\n",
    "    \"Counterparty\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"counterparties.csv\", \n",
    "        \"label\": \"Counterparty\", \n",
    "        \"unique_column_name\": \"counterparty_id\", \n",
    "        \"properties\": [\"counterparty_name\", \"lei_code\", \"counterparty_type\", \"rating\", \"jurisdiction\"]\n",
    "    },\n",
    "    \"BELONGS_TO_ACCOUNT\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"positions.csv\", \n",
    "        \"relationship_type\": \"BELONGS_TO\", \n",
    "        \"from_node_label\": \"Position\", \n",
    "        \"from_node_column\": \"position_id\", \n",
    "        \"to_node_label\": \"Account\", \n",
    "        \"to_node_column\": \"account_id\", \n",
    "        \"properties\": [\"quantity\"]\n",
    "    }, \n",
    "    \"BELONGS_TO_BOOK\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"accounts.csv\", \n",
    "        \"relationship_type\": \"BELONGS_TO\", \n",
    "        \"from_node_label\": \"Account\", \n",
    "        \"from_node_column\": \"account_id\", \n",
    "        \"to_node_label\": \"Book\", \n",
    "        \"to_node_column\": \"book_id\", \n",
    "        \"properties\": []\n",
    "    },\n",
    "    \"BELONGS_TO_DESK\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"books.csv\", \n",
    "        \"relationship_type\": \"BELONGS_TO\", \n",
    "        \"from_node_label\": \"Book\", \n",
    "        \"from_node_column\": \"book_id\", \n",
    "        \"to_node_label\": \"Desk\", \n",
    "        \"to_node_column\": \"desk_id\", \n",
    "        \"properties\": []\n",
    "    },\n",
    "    \"BELONGS_TO_ENTITY\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"desks.csv\", \n",
    "        \"relationship_type\": \"BELONGS_TO\", \n",
    "        \"from_node_label\": \"Desk\", \n",
    "        \"from_node_column\": \"desk_id\", \n",
    "        \"to_node_label\": \"LegalEntity\", \n",
    "        \"to_node_column\": \"legal_entity_id\", \n",
    "        \"properties\": []\n",
    "    },\n",
    "    \"REFERENCES_INSTRUMENT_POSITION\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"positions.csv\", \n",
    "        \"relationship_type\": \"REFERENCES\", \n",
    "        \"from_node_label\": \"Position\", \n",
    "        \"from_node_column\": \"position_id\", \n",
    "        \"to_node_label\": \"Instrument\", \n",
    "        \"to_node_column\": \"instrument_id\", \n",
    "        \"properties\": []\n",
    "    },\n",
    "    \"REFERENCES_INSTRUMENT_TRADE\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"trades.csv\", \n",
    "        \"relationship_type\": \"REFERENCES\", \n",
    "        \"from_node_label\": \"Trade\", \n",
    "        \"from_node_column\": \"trade_id\", \n",
    "        \"to_node_label\": \"Instrument\", \n",
    "        \"to_node_column\": \"instrument_id\", \n",
    "        \"properties\": []\n",
    "    },\n",
    "    \"ALLOCATED_TO\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"trade_allocations.csv\", \n",
    "        \"relationship_type\": \"ALLOCATED_TO\", \n",
    "        \"from_node_label\": \"Trade\", \n",
    "        \"from_node_column\": \"trade_id\", \n",
    "        \"to_node_label\": \"Account\", \n",
    "        \"to_node_column\": \"account_id\", \n",
    "        \"properties\": [\"allocation_quantity\", \"allocation_percentage\", \"allocation_timestamp\"]\n",
    "    },\n",
    "    \"TRADES_WITH\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"trades.csv\", \n",
    "        \"relationship_type\": \"TRADES_WITH\", \n",
    "        \"from_node_label\": \"Trade\", \n",
    "        \"from_node_column\": \"trade_id\", \n",
    "        \"to_node_label\": \"Counterparty\", \n",
    "        \"to_node_column\": \"counterparty_id\", \n",
    "        \"properties\": []\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "construct_domain_graph(approved_construction_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Inspect the Position Management Domain Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell filters the construction plan to extract only the relationship construction rules. This list will be used in the next cell to verify that all relationships were successfully created in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 114
   },
   "outputs": [],
   "source": [
    "# extract a list of the relationship construction rules\n",
    "relationship_constructions = [\n",
    "    value for value in approved_construction_plan.values()\n",
    "    if value.get(\"construction_type\") == \"relationship\"\n",
    "]\n",
    "relationship_constructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates and executes a Cypher query to verify that all relationship types from the position management construction plan were successfully created in the graph. \n",
    "\n",
    "The query uses several advanced Cypher features:\n",
    "- `UNWIND`: Iterates through each relationship construction rule\n",
    "- `CALL (construction) { ... }`: Subquery that executes for each construction rule\n",
    "- `MATCH (from)-[r:relationship_type]->(to)`: Finds one example of each relationship type (BELONGS_TO, ALLOCATED_TO, REFERENCES, TRADES_WITH)\n",
    "- `LIMIT 1`: Returns only one example per relationship type\n",
    "\n",
    "This provides a summary view showing one instance of each relationship pattern in the constructed position management graph, verifying the complete hierarchy from Trade through Position, Account, Book, Desk to LegalEntity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 558
   },
   "outputs": [],
   "source": [
    "# a fancy cypher query which to show one instance of each construction rule\n",
    "\n",
    "# turn the list of rules into multiple single rules\n",
    "unwind_list = \"UNWIND $relationship_constructions AS construction\"\n",
    "\n",
    "# match a single path for a given construction.relationship_type\n",
    "# return only the labels and types from the 3 parts of the path\n",
    "match_one_path = \"\"\"\n",
    "    MATCH (from)-[r:$(construction.relationship_type)]->(to)\n",
    "    RETURN labels(from) AS fromNode, type(r) AS relationship, labels(to) AS toNode\n",
    "    LIMIT 1\n",
    "\"\"\"\n",
    "match_in_subquery = f\"\"\"\n",
    "CALL (construction) {{\n",
    "{match_one_path}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "cypher = f\"\"\"\n",
    "{unwind_list}\n",
    "{match_in_subquery}\n",
    "RETURN fromNode, relationship, toNode\n",
    "\"\"\"\n",
    "\n",
    "print(cypher)\n",
    "\n",
    "print(\"\\n---\")\n",
    "\n",
    "graphdb.send_query(cypher, {\n",
    "    \"relationship_constructions\": relationship_constructions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
